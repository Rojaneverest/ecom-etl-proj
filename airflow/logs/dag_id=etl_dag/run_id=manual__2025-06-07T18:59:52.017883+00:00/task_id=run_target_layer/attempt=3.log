[2025-06-07T19:10:24.107+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_dag.run_target_layer manual__2025-06-07T18:59:52.017883+00:00 [queued]>
[2025-06-07T19:10:24.113+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_dag.run_target_layer manual__2025-06-07T18:59:52.017883+00:00 [queued]>
[2025-06-07T19:10:24.113+0000] {taskinstance.py:2170} INFO - Starting attempt 3 of 4
[2025-06-07T19:10:24.119+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): run_target_layer> on 2025-06-07 18:59:52.017883+00:00
[2025-06-07T19:10:24.126+0000] {standard_task_runner.py:60} INFO - Started process 632 to run task
[2025-06-07T19:10:24.129+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'etl_dag', 'run_target_layer', 'manual__2025-06-07T18:59:52.017883+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/tmp/tmpicgjk6a2']
[2025-06-07T19:10:24.130+0000] {standard_task_runner.py:88} INFO - Job 50: Subtask run_target_layer
[2025-06-07T19:10:24.168+0000] {task_command.py:423} INFO - Running <TaskInstance: etl_dag.run_target_layer manual__2025-06-07T18:59:52.017883+00:00 [running]> on host c183c35f0e34
[2025-06-07T19:10:24.235+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='etl_dag' AIRFLOW_CTX_TASK_ID='run_target_layer' AIRFLOW_CTX_EXECUTION_DATE='2025-06-07T18:59:52.017883+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-07T18:59:52.017883+00:00'
[2025-06-07T19:10:24.238+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-06-07T19:10:24.240+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'cd /opt/***/ecom_etl && python target_layer.py']
[2025-06-07T19:10:24.253+0000] {subprocess.py:86} INFO - Output:
[2025-06-07T19:10:24.908+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:24,907 - snowflake_dwh_script - INFO - --- Starting Snowflake DWH Load Script ---
[2025-06-07T19:10:24.909+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:24,907 - snowflake.connector.connection - INFO - Snowflake Connector for Python Version: 3.6.0, Python Version: 3.8.18, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.34
[2025-06-07T19:10:24.909+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:24,907 - snowflake.connector.connection - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-06-07T19:10:25.941+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:25,940 - snowflake_dwh_script - INFO - Successfully connected to Snowflake.
[2025-06-07T19:10:25.951+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:25,940 - snowflake_dwh_script - INFO - Ensuring database 'ECOM_DWH' and schema 'PUBLIC' exist...
[2025-06-07T19:10:25.952+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:25,940 - snowflake_dwh_script - ERROR - An error occurred during the DWH loading process: name 'execute_query' is not defined
[2025-06-07T19:10:27.842+0000] {subprocess.py:93} INFO - Logs uploaded to s3://rj-ecom-etl/reports/processed_reports/dwh_load_log_20250607_191024.txt
[2025-06-07T19:10:27.854+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:27,840 - snowflake.connector.connection - INFO - closed
[2025-06-07T19:10:28.110+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:28,109 - snowflake.connector.connection - INFO - No async queries seem to be running, deleting session
[2025-06-07T19:10:28.687+0000] {subprocess.py:93} INFO - 2025-06-07 19:10:28,685 - snowflake_dwh_script - INFO - Snowflake connection closed.
[2025-06-07T19:10:28.859+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-06-07T19:10:28.884+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-06-07T19:10:28.887+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=etl_dag, task_id=run_target_layer, execution_date=20250607T185952, start_date=20250607T191024, end_date=20250607T191028
[2025-06-07T19:10:28.903+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 50 for task run_target_layer (Bash command failed. The command returned a non-zero exit code 1.; 632)
[2025-06-07T19:10:28.919+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-06-07T19:10:28.950+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
